---
title: Machine Precision Derivatives
author: Keith A. Lewis
copyright: Â© 2019
classoption: fleqn
abstract: |
	This short note demonstrates a method for computing mixed partial derivatives to machine precision.
...

Suppose there were a "number" $\epsilon$ such that $\epsilon\not=0$ but
$\epsilon^2 = 0$. If $f$ is differentiable at $x$ then, using the Taylor
series expansion,
$$
	f(x + \epsilon) = f(x) + f'(x) \epsilon.
$$
For example, if $f(x) = x^2$ then $(x + \epsilon)^2 = x^2 + 2x\epsilon$
so $f'(x) = 2x$.

There is such a "number", the $2\times 2$ matrix $\epsilon =
\begin{bmatrix}0&1\\0&0\end{bmatrix}$.  No need to compute limits of
difference quotients\cite{?} or drag in Automatic Differentiation\cite{?} machinery.

It is possible use this method to compute arbitrary derivatives to machine precision, including
mixed partial derivatives.

## Functional Calculus

Functions on numbers can be extended to functions on linear operators
using a _functional calculus_\cite{?}. If $T\colon V\to V$ is a linear operator
on the vector space $V$ and $p$ is a polynomial, then $p(T)$ can be
defined in the obvious way. If $q$ is a polynomial and $q(T)$ is
invertible, then we can define $(p/q)(T) = p(T)q(T)^{-1}$ for
appropriate rational functons.

If $V$ is a Banach space we can use power series.  If $f$ is sufficiently
differentiable, $f(x) = \sum_{n\ge0} f^{(n)}(0) x^n/n!$ and
$f(T) = \sum_{n\ge0} f^{(n)}(0) T^n/n!$ exists whenever $\|T\|$
is less than the radius of convergence of the series.

Every vector space, $V$, of dimension $n$ has a linear operator $\epsilon\colon V\to V$
with $I$, $\epsilon$, \ldots, $\epsilon^{n-1}$ independent. E.g., if $e_1$, \ldots, $e_n$
is a basis of $V$ define $\epsilon e_1 = 0$ and $\epsilon e_j = e_{j-1}$ for $1 < j \le n$.
If $V = \mathbf{R}^n$ with the standard basis, $\epsilon$ is the matrix with $1$'s above
the main diagonal and $0$'s elsewhere. The algebra generated by $\epsilon$ is the
upper triangular Toepliz matrices.

## Univariate Derivatives

Suppose $f\colon\mathbf{R}\to\mathbf{R}$ has derivatives to order $n$. The Taylor series expansion is
$$
	f(xI + \epsilon) = \sum_{k=0}^{n-1} \frac{D^k f(x)}{k!}\epsilon^k,
$$
since $\epsilon^{n+k} = 0$ for $k\ge 0$. Note $D^k f = f^{k}$ is the $k$-th derivative of $f$.

For example, if $f(x) = \exp(x) = \sum_{k\ge0} x^k/k!$ then
\begin{align*}
\exp(xI + \epsilon) &= \sum_{k\ge0} (xI + \epsilon)^k/k!\\
&= \sum_{k\ge0} \sum_{j=0}^k \binom{k}{j} x^j\epsilon^{k-j}/k!\\
&= \sum_{j\ge0} \sum_{k\ge j} x^j\epsilon^{k-j}/j!(k - j)!\\
&= \sum_{j\ge0} \sum_{k\ge 0} x^j\epsilon^{k}/j!k!\\
&= \sum_{k\ge0} \sum_{j\ge 0} x^j\epsilon^{k}/j!k!\\
&= \sum_{k\ge0} \exp(x)\epsilon^{k}/k!.\\
\end{align*}
This shows $D^k\exp(x) = \exp(x)$ for all $k$.


## Multivariate Derivatives

It is also possible to compute mixed derivatives to machine precision.
Suppose $f\colon\mathbf{R}^n\to\mathbf{R}$. The Taylor series expansion is
$$
	f(x + \epsilon) = \sum_{k\ge0} \sum_{|\alpha|=k} \frac{D^\alpha f(x)}{\alpha!}\epsilon^\alpha,
$$
where $x = (x_1,\ldots,x_n)$,
$\epsilon = (\epsilon_1,\ldots,\epsilon_n$),
$\alpha = (\alpha_1, \ldots, \alpha_n)$,
$|\alpha| = \alpha_1 + \cdots + \alpha_n$,
$D^\alpha f(x) = \partial^{|\alpha|}f(x_1,\ldots,x_n)/\partial^{\alpha_1} x_1\cdots\partial^{\alpha_n} x_n$,
$\alpha! = \alpha_1!\cdots\alpha_n!$,
and $\epsilon^\alpha = \epsilon_1^{\alpha_1}\cdots\epsilon_n^{\alpha_n}$,
a triumph of mathematical notation if there ever was one.

## Computer Implementaton

For the univariate case the algebra generated by $\epsilon$ of order $n$ has dimension
$n$. There is an isomorphism with $\mathbf{R}^n$ via $(a_j)_{0\le j<n}\to\sum_{0\le j<n} a_j \epsilon^n/j!$.
It is convenient to include the factorial in the denominators to map directly to
derivatives and for numerical stability.

Obviously, addition and subtraction correspond to the usual vector space operations on $\mathbf{R}^n$.
Multiplication is $(a_i)(b_j) = (c_k)$ where $c_k = \sum_{i = 0}^{n - 1} \binom{k}{i} a_i b_{k - i}$.

Map $f(xI + \epsilon)$ to $(f^{(n)}(x)/n!)$.

## Remarks

If $f$ is _analytic_ in a neighborhood of $\sigma(T)$, the spectrum of $T$ ...

## NOTES

Apache Java math project

http://commons.apache.org/proper/commons-math/

http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math4/analysis/differentiation/DerivativeStructure.html

Computer implemtation only involve $f(xI + \epsilon)$. The rest is taken care of by Toeplitz matrix mulitplication.
